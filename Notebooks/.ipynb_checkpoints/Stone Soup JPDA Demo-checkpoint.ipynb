{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Stone_Soup_Icon_Final_small.png\">\n",
    "<h1>Stone Soup Joint Probabiliistic Data Association (JPDA) Demo</h1>\n",
    "Demonstrating the capabilities of the Stone Soup JPDA filter.\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Initially, we'll set up some initial import and a plotting method which we'll use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#General imports and plotting\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "def plot_data(groundtruth_paths, detections, tracks):\n",
    "    from stonesoup.types.detection import Clutter\n",
    "    data = np.array([detection.state_vector for detection in detections if not isinstance(detection, Clutter)])\n",
    "    if data.any():\n",
    "        plt.plot(data[:,0], data[:, 1], linestyle='', marker='o')\n",
    "\n",
    "    data = np.array([detection.state_vector for detection in detections if isinstance(detection, Clutter)])\n",
    "    if data.any():\n",
    "        plt.plot(data[:,0], data[:, 1], linestyle='', marker='2')\n",
    "\n",
    "    for path in groundtruth_paths:\n",
    "        data = np.array([state.state_vector for state in path])\n",
    "        plt.plot(data[:, 0], data[:, 2], linestyle=':', marker='')\n",
    "\n",
    "    from stonesoup.types.prediction import Prediction\n",
    "    for track in tracks:\n",
    "        if len([state for state in track.states if not isinstance(state, Prediction)]) < 2:\n",
    "            continue  # Don't plot tracks with only one detection associated; probably clutter\n",
    "        data = np.array([state.state_vector for state in track.states])\n",
    "        plt.plot(data[:, 0], data[:, 2], linestyle='-', marker='.')\n",
    "        if hasattr(track.state, 'particles'):\n",
    "            data = np.array([particle.state_vector for state in track.states for particle in state.particles])\n",
    "            plt.plot(data[:,0], data[:,2], linestyle='', marker=\".\", markersize=1, alpha=0.5)\n",
    "\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$y$\")\n",
    "    custom_legend = [\n",
    "        matplotlib.lines.Line2D([0], [0], color='0', linestyle='', marker='o'),\n",
    "        matplotlib.lines.Line2D([0], [0], color='0', linestyle='', marker='2'),\n",
    "        matplotlib.lines.Line2D([0], [0], color='0', linestyle=':', marker=''),\n",
    "        matplotlib.lines.Line2D([0], [0], color='0', linestyle='-', marker='.'),\n",
    "        matplotlib.lines.Line2D([0], [0], color='0', linestyle='', marker='.', markersize=1),\n",
    "    ]\n",
    "    plt.legend(custom_legend,\n",
    "               ['Detections', 'Clutter', 'Path', 'Track', 'Particles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Generating Data\n",
    "----------------\n",
    "First we'll create some models, which will be used to generate data.\n",
    "\n",
    "This will include a 2D-position constant velocity transition model ($x$, $\\dot{x}$, $y$ and $\\dot{y}$) generated by combining two 1D models (this allows multiple models to be mixed and generation of *n*-dimension models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel,\\\n",
    "                                               ConstantVelocity\n",
    "transition_model = CombinedLinearGaussianTransitionModel(\n",
    "    (ConstantVelocity(1), ConstantVelocity(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And a measurement model, which will map the position based detections ($x$ and $y$) to the position in the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4, mapping=[0, 2], noise_covar=np.diag([10, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next we'll create a multi-target ground truth simulation in order to generate some data for testing the tracking algorithms. This utilises the *transition model* to generate the ground truth paths, initialised at random by sampling from a *Gaussian State*. A ground truth track/path at each timestamp is created at a random *birth rate* ($\\lambda$ in Poisson distribution), and randomly killed by a *death probability*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.simulator.simple import MultiTargetGroundTruthSimulator\n",
    "from stonesoup.types.state import GaussianState\n",
    "from stonesoup.types.array import StateVector, CovarianceMatrix\n",
    "\n",
    "groundtruth_sim = MultiTargetGroundTruthSimulator(\n",
    "    transition_model=transition_model,\n",
    "    initial_state=GaussianState(\n",
    "        StateVector([[0], [0], [0], [0]]),\n",
    "        CovarianceMatrix(np.diag([1000000, 10, 1000000, 10]))),\n",
    "    timestep=datetime.timedelta(seconds=5),\n",
    "    birth_rate=0.3,\n",
    "    death_probability=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next we'll create a detection simulator which will generate detections based on a *detection probability* about the ground truth, utilising the *measurement model*. This model will also create clutter in our defined *measurement range*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.simulator.simple import SimpleDetectionSimulator\n",
    "\n",
    "detection_sim = SimpleDetectionSimulator(\n",
    "    groundtruth=groundtruth_sim,\n",
    "    measurement_model=measurement_model,\n",
    "    meas_range=np.array([[-1, 1], [-1, 1]])*5000,  # Area to generate clutter\n",
    "    detection_probability=0.9,\n",
    "    clutter_rate=3,\n",
    ")\n",
    "\n",
    "detections_source = detection_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Building JPDA Kalman tracker components\n",
    "------------------------------------\n",
    "\n",
    "With the detection data ready, we'll now build a JPDA Kalman tracker. For this we will need a Kalman predictor, which will utilise the same *transition model* we used in the ground truth simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.predictor.kalman import KalmanPredictor\n",
    "predictor = KalmanPredictor(transition_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And a PDA Kalman updater, utilising the same *measurement model* we used in the detection simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.updater.kalman import PDAKalmanUpdater\n",
    "updater = PDAKalmanUpdater(measurement_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will also need a data associator to link detections to tracks for the update step.  For information on how the JPDA filter does this, please refer to the following references:\n",
    "\n",
    "https://pdfs.semanticscholar.org/ecc7/0452659dfb0bc0190632f3169e53f9281395.pdf\n",
    "http://www.cse.psu.edu/~rtc12/CSE598C/datassocPart2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.hypothesiser.probability import PDAHypothesiser\n",
    "hypothesiser = PDAHypothesiser(predictor, updater, clutter_spatial_density=detection_sim.clutter_spatial_density, prob_detect=0.9, prob_gate=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.dataassociator.probability import JPDA\n",
    "data_associator = JPDA(hypothesiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And finally a initiator to generate tracks from unassociated detections, in this case a single point initiator generating a track for every unassociated detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.initiator.simple import SinglePointInitiator\n",
    "initiator = SinglePointInitiator(\n",
    "    GaussianState(np.array([[0], [0], [0], [0]]), np.diag([10000, 100, 10000, 1000])),\n",
    "    measurement_model=measurement_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And a deleter to remove tracks, for this demo simply based on large covariance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.deleter.simple import CovarianceBasedDeleter\n",
    "deleter = CovarianceBasedDeleter(covar_trace_thresh=1E3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Running the JPDA Kalman tracker\n",
    "---------------------------\n",
    "With all the components in place, we'll now construct the tracker with a multi target tracker. Since the JPDA filter is more computationally intensive than other algorithms (due to the combinatorial explosion of permutations of track/detection associations), this notebook prints the current simulation time being processed so that you can see that the algorithm is not \"hanging\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from stonesoup.tracker.simple import MultiTargetTracker\n",
    "tracker = MultiTargetTracker(\n",
    "    initiator=initiator,\n",
    "    deleter=deleter,\n",
    "    detector=detections_source,\n",
    "    data_associator=data_associator,\n",
    "    updater=updater,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  2019-01-10 15:16:40.488353\n",
      "Time:  2019-01-10 15:16:45.488353\n",
      "Time:  2019-01-10 15:16:50.488353\n",
      "Time:  2019-01-10 15:16:55.488353\n",
      "Time:  2019-01-10 15:17:00.488353\n",
      "Time:  2019-01-10 15:17:05.488353\n",
      "Time:  2019-01-10 15:17:10.488353\n",
      "Time:  2019-01-10 15:17:15.488353\n",
      "Time:  2019-01-10 15:17:20.488353\n",
      "Time:  2019-01-10 15:17:25.488353\n",
      "Time:  2019-01-10 15:17:30.488353\n",
      "Time:  2019-01-10 15:17:35.488353\n",
      "Time:  2019-01-10 15:17:40.488353\n",
      "Time:  2019-01-10 15:17:45.488353\n",
      "Time:  2019-01-10 15:17:50.488353\n",
      "Time:  2019-01-10 15:17:55.488353\n",
      "Time:  2019-01-10 15:18:00.488353\n",
      "Time:  2019-01-10 15:18:05.488353\n",
      "Time:  2019-01-10 15:18:10.488353\n",
      "Time:  2019-01-10 15:18:15.488353\n",
      "Time:  2019-01-10 15:18:20.488353\n",
      "Time:  2019-01-10 15:18:25.488353\n",
      "Time:  2019-01-10 15:18:30.488353\n",
      "Time:  2019-01-10 15:18:35.488353\n",
      "Time:  2019-01-10 15:18:40.488353\n",
      "Time:  2019-01-10 15:18:45.488353\n",
      "Time:  2019-01-10 15:18:50.488353\n",
      "Time:  2019-01-10 15:18:55.488353\n",
      "Time:  2019-01-10 15:19:00.488353\n",
      "Time:  2019-01-10 15:19:05.488353\n",
      "Time:  2019-01-10 15:19:10.488353\n",
      "Time:  2019-01-10 15:19:15.488353\n",
      "Time:  2019-01-10 15:19:20.488353\n",
      "Time:  2019-01-10 15:19:25.488353\n",
      "Time:  2019-01-10 15:19:30.488353\n",
      "Time:  2019-01-10 15:19:35.488353\n",
      "Time:  2019-01-10 15:19:40.488353\n",
      "Time:  2019-01-10 15:19:45.488353\n",
      "Time:  2019-01-10 15:19:50.488353\n",
      "Time:  2019-01-10 15:19:55.488353\n",
      "Time:  2019-01-10 15:20:00.488353\n",
      "Time:  2019-01-10 15:20:05.488353\n",
      "Time:  2019-01-10 15:20:10.488353\n",
      "Time:  2019-01-10 15:20:15.488353\n",
      "Time:  2019-01-10 15:20:20.488353\n",
      "Time:  2019-01-10 15:20:25.488353\n",
      "Time:  2019-01-10 15:20:30.488353\n",
      "Time:  2019-01-10 15:20:35.488353\n",
      "Time:  2019-01-10 15:20:40.488353\n",
      "Time:  2019-01-10 15:20:45.488353\n",
      "Time:  2019-01-10 15:20:50.488353\n",
      "Time:  2019-01-10 15:20:55.488353\n",
      "Time:  2019-01-10 15:21:00.488353\n",
      "Time:  2019-01-10 15:21:05.488353\n",
      "Time:  2019-01-10 15:21:10.488353\n",
      "Time:  2019-01-10 15:21:15.488353\n",
      "Time:  2019-01-10 15:21:20.488353\n",
      "Time:  2019-01-10 15:21:25.488353\n",
      "Time:  2019-01-10 15:21:30.488353\n",
      "Time:  2019-01-10 15:21:35.488353\n",
      "Time:  2019-01-10 15:21:40.488353\n",
      "Time:  2019-01-10 15:21:45.488353\n",
      "Time:  2019-01-10 15:21:50.488353\n",
      "Time:  2019-01-10 15:21:55.488353\n",
      "Time:  2019-01-10 15:22:00.488353\n",
      "Time:  2019-01-10 15:22:05.488353\n",
      "Time:  2019-01-10 15:22:10.488353\n",
      "Time:  2019-01-10 15:22:15.488353\n",
      "Time:  2019-01-10 15:22:20.488353\n",
      "Time:  2019-01-10 15:22:25.488353\n",
      "Time:  2019-01-10 15:22:30.488353\n",
      "Time:  2019-01-10 15:22:35.488353\n",
      "Time:  2019-01-10 15:22:40.488353\n",
      "Time:  2019-01-10 15:22:45.488353\n",
      "Time:  2019-01-10 15:22:50.488353\n",
      "Time:  2019-01-10 15:22:55.488353\n",
      "Time:  2019-01-10 15:23:00.488353\n",
      "Time:  2019-01-10 15:23:05.488353\n",
      "Time:  2019-01-10 15:23:10.488353\n",
      "Time:  2019-01-10 15:23:15.488353\n",
      "Time:  2019-01-10 15:23:20.488353\n",
      "Time:  2019-01-10 15:23:25.488353\n",
      "Time:  2019-01-10 15:23:30.488353\n",
      "Time:  2019-01-10 15:23:35.488353\n",
      "Time:  2019-01-10 15:23:40.488353\n",
      "Time:  2019-01-10 15:23:45.488353\n",
      "Time:  2019-01-10 15:23:50.488353\n",
      "Time:  2019-01-10 15:23:55.488353\n",
      "Time:  2019-01-10 15:24:00.488353\n",
      "Time:  2019-01-10 15:24:05.488353\n",
      "Time:  2019-01-10 15:24:10.488353\n",
      "Time:  2019-01-10 15:24:15.488353\n",
      "Time:  2019-01-10 15:24:20.488353\n",
      "Time:  2019-01-10 15:24:25.488353\n",
      "Time:  2019-01-10 15:24:30.488353\n",
      "Time:  2019-01-10 15:24:35.488353\n",
      "Time:  2019-01-10 15:24:40.488353\n",
      "Time:  2019-01-10 15:24:45.488353\n",
      "Time:  2019-01-10 15:24:50.488353\n",
      "Time:  2019-01-10 15:24:55.488353\n"
     ]
    }
   ],
   "source": [
    "tracks = set()\n",
    "groundtruth_paths = set()  # Store for plotting later\n",
    "detections = set()  # Store for plotting later\n",
    "for time, ctracks in tracker.tracks_gen():\n",
    "    tracks.update(ctracks)\n",
    "    detections |= tracker.detector.detections\n",
    "    #groundtruth_paths = groundtruth_paths\n",
    "    print(\"Time: \", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_data(groundtruth_paths, detections, tracks);plt.title(\"2D Kalman tracker\");\n",
    "plt.xlim(-3000, 3000);\n",
    "plt.ylim(-3000, 3000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Note: Colours are random to help differentiate overlapping data."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
